{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## DSIT 2021 BIG DATA ANALYTICS KAGGLE KERNEL\n",
    "### Word2Vec + XGBoost Quora question similarity"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Import Libraries used"
   ]
  },
  {
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from tqdm.notebook import tqdm\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial.distance import cosine\n",
    "import time\n",
    "import multiprocessing"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define some helper functions to be used later"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "def tokenize_text(text):\n",
    "    text = str(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [w for w in word_tokens if not w in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "def jaccard_sim(text1, text2):\n",
    "    tk_text1 = set(tokenize_text(text1))\n",
    "    tk_text2 = set(tokenize_text(text2))\n",
    "    j_sim = float(len(tk_text1.intersection(tk_text2)) / len(tk_text1.union(tk_text2)))\n",
    "    j_sim = np.nan_to_num(j_sim, posinf=100, neginf=0)\n",
    "    return int(j_sim * 100)\n",
    "\n",
    "\n",
    "def fuzzy_score(text1, text2):\n",
    "    f_score = fuzz.token_set_ratio(text1, text2)\n",
    "    return f_score\n",
    "\n",
    "def wmd(q1, q2, model):\n",
    "    q1 = tokenize_text(q1)\n",
    "    q2 = tokenize_text(q2)\n",
    "    return model.wv.wmdistance(q1, q2)\n",
    "\n",
    "def q2vec(q, model):\n",
    "    q = tokenize_text(q)\n",
    "    V = []\n",
    "    for w in q:\n",
    "        try:\n",
    "            V.append(model.wv[w])\n",
    "        except:\n",
    "            continue\n",
    "    if len(V)==0:\n",
    "        V = np.zeros(300)\n",
    "    else:\n",
    "        V = np.array(V)\n",
    "    return np.mean(V, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cross_val(clf, X, y, k=5):\n",
    "    # perform k fold cross validation and print the requested metrics\n",
    "    # if to_file = True write the requested metrics to a file\n",
    "    print(\"Attempting 5-fold cross validation...\")\n",
    "    scoring = {\n",
    "        'acc': 'accuracy',\n",
    "        'prec_macro': 'precision_macro',\n",
    "        'rec_macro': 'recall_macro',\n",
    "        'f1_macro': 'f1_macro'\n",
    "\n",
    "    }\n",
    "    scores = cross_validate(clf, X, y, cv=k, scoring=scoring, return_train_score=False, n_jobs=2)\n",
    "    print('Accuracy:', np.mean(scores['test_acc']), scores['test_acc'])\n",
    "    print('Precision:', np.mean(scores['test_prec_macro']), scores['test_prec_macro'])\n",
    "    print('Recall:', np.mean(scores['test_rec_macro']), scores['test_rec_macro'])\n",
    "    print('F-Measure:', np.mean(scores['test_f1_macro']), scores['test_f1_macro'])\n",
    "    print('Fit-Time:', np.mean(scores['fit_time']), scores['fit_time'])"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### We start off by reading our training data and tokenizing"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../input/2b-training/train.csv')\n",
    "print('Tokenizing Questions...')\n",
    "list_of_lists = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    list_of_lists.append(tokenize_text(row['Question1']))\n",
    "    list_of_lists.append(tokenize_text(row['Question2']))\n",
    "print(len(list_of_lists))\n",
    "\n"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": "Tokenizing Questions...\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9a3af12fd33466ab80488e5d3b3695c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\n566008\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Instantiate the Word2Vec gensim model and build its vocabulary"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model = gensim.models.Word2Vec(size=300, window=5, min_count=5, sg=1, workers=cores)\n",
    "model.save(\"word2vec.model\") # save the model for later usage\n",
    "t = time.time()\n",
    "model.build_vocab(list_of_lists, progress_per=10000)\n",
    "print('Time to build vocab: {} mins'.format(round((time.time() - t) / 60, 2)))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": "Time to build vocab: 0.2 mins\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train the Word2Vec gensim model for 30 epochs"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "t = time.time()\n",
    "\n",
    "model.train(list_of_lists, total_examples = model.corpus_count, epochs=30, report_delay=1)\n",
    "#model = gensim.models.Word2Vec.load(\"word2vec.model\") # a pretrained model can  be loaded\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time.time() - t) / 60, 2)))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": "Time to train the model: 5.68 mins\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### After training our model we generate the question embeddings (vectors)\n",
    "### We also generate our hand-crafted features"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "question1_vectors = np.zeros((df.shape[0], 300))\n",
    "for i, q in enumerate(tqdm(df.Question1.values)):\n",
    "    question1_vectors[i, :] = q2vec(q, model)\n",
    "    \n",
    "question2_vectors  = np.zeros((df.shape[0], 300))\n",
    "for i, q in enumerate(tqdm(df.Question2.values)):\n",
    "    question2_vectors[i, :] = q2vec(q, model)\n",
    "\n",
    "np.save('q1_vectors', question1_vectors)\n",
    "np.save('q2_vectors', question2_vectors)\n",
    "\n",
    "df['fuzz_token_set_ratio'] = df.apply(lambda x: fuzz.token_set_ratio(str(x['Question1']), str(x['Question2'])), axis=1)\n",
    "print(\"fuzzy done\")\n",
    "df['jaccard_score'] = df.apply(lambda x: jaccard_sim(str(x['Question1']), str(x['Question2'])), axis=1)\n",
    "print(\"jaccard done\")\n",
    "df['wmd'] = df.apply(lambda x: wmd(x['Question1'], x['Question2'], model), axis=1)\n",
    "print(\"wmd done\")\n",
    "df['cos_sim'] = [cosine(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors, posinf=1, neginf=0), np.nan_to_num(question2_vectors, posinf=1, neginf=0))]\n",
    "print(\"cosine done\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.drop(['Id', 'Question1', 'Question2'], axis=1, inplace=True)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=283004.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6c0beca41ae48eaacca9eea23e5d5b6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=283004.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "642a5fccf469460aafd86dc7b089e705"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\nfuzzy done\njaccard done\nwmd done\n",
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": "/opt/conda/lib/python3.7/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": "cosine done\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# vectorize and extrac features from the test set\n",
    "df_test = pd.read_csv('../input/2b-training/test_without_labels.csv')\n",
    "\n",
    "question1_vectors_test = np.zeros((df_test.shape[0], 300))\n",
    "for i, q in enumerate(tqdm(df_test.Question1.values)):\n",
    "    question1_vectors_test[i, :] = q2vec(q, model)\n",
    "    \n",
    "question2_vectors_test  = np.zeros((df_test.shape[0], 300))\n",
    "for i, q in enumerate(tqdm(df_test.Question2.values)):\n",
    "    question2_vectors_test[i, :] = q2vec(q, model)\n",
    "    \n",
    "np.save('q1_vectors_test', question1_vectors_test)\n",
    "np.save('q2_vectors_test', question2_vectors_test)\n",
    "    \n",
    "df_test['fuzz_token_set_ratio'] = df_test.apply(lambda x: fuzz.token_set_ratio(str(x['Question1']), str(x['Question2'])), axis=1)\n",
    "print(\"fuzzy done\")\n",
    "df_test['jaccard_score'] = df_test.apply(lambda x: jaccard_sim(str(x['Question1']), str(x['Question2'])), axis=1)\n",
    "print(\"jaccard done\")\n",
    "df_test['wmd'] = df_test.apply(lambda x: wmd(x['Question1'], x['Question2'], model), axis=1)\n",
    "print(\"wmd done\")\n",
    "df_test['cos_sim'] = [cosine(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors_test, posinf=1, neginf=0), np.nan_to_num(question2_vectors_test, posinf=1, neginf=0))]\n",
    "print(\"cosine done\")\n",
    "\n",
    "df_test.head()\n",
    "\n",
    "df_test.drop(['Id', 'Question1', 'Question2'], axis=1, inplace=True)"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=121287.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f93ec106ace4458fbe9b8d855d94776e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=121287.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "adace0f8e983405dbf39fbe02d57ff99"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "text": "\nfuzzy done\njaccard done\nwmd done\ncosine done\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# clean training df\n",
    "#df = pd.read_csv('out.csv')\n",
    "df.isnull().sum()\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "# clean test df\n",
    "df_test.isnull().sum()\n",
    "df_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_test= df_test.fillna(df_test.mean())"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create the training set, test set as well as our labels"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "df.head()\n",
    "X = df.loc[:, df.columns != 'IsDuplicate']\n",
    "y = df.loc[:, df.columns == 'IsDuplicate']\n",
    "X_test = df_test.loc[:, df_test.columns != 'IsDuplicate']\n",
    "normalizer = preprocessing.Normalizer()\n",
    "X = normalizer.fit_transform(X)\n",
    "X_test = normalizer.fit_transform(X_test)"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generate our finalized training and test set by stacking our word vectors and custom features"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "q1_train = question1_vectors\n",
    "q2_train = question2_vectors\n",
    "q1_test = question1_vectors_test\n",
    "q2_test = question2_vectors_test\n",
    "\n",
    "print(q1_train.shape)\n",
    "print(q2_train.shape)\n",
    "print(q1_test.shape)\n",
    "print(q2_test.shape)\n",
    "full_train = np.hstack((q1_train, q2_train, X))\n",
    "full_test = np.hstack((q1_test, q2_test, X_test))\n",
    "\n",
    "print(full_train.shape)\n",
    "print(full_test.shape)\n"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": "(283004, 300)\n(283004, 300)\n(121287, 300)\n(121287, 300)\n(283004, 604)\n(121287, 604)\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Finally Use a model to classify our questions as duplicates or not"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import xgboost as xgb\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df[\"IsDuplicate\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MAX_TREE_DEPTH = 8\n",
    "TREE_METHOD = 'gpu_hist'\n",
    "ITERATIONS = 1000\n",
    "SUBSAMPLE = 1\n",
    "REGULARIZATION = 0.0\n",
    "GAMMA = 0\n",
    "POS_WEIGHT = 1\n",
    "EARLY_STOP = 10\n",
    "\n",
    "clf = xgb.XGBClassifier(tree_method = 'gpu_hist', n_estimators=200, random_state=0, max_depth=MAX_TREE_DEPTH, alpha=REGULARIZATION, gamma=GAMMA, subsample=SUBSAMPLE,\n",
    "                          scale_pos_weight=POS_WEIGHT, learning_rate=0.01, silent=1, objective='binary:logistic', early_stopping_rounds=EARLY_STOP,\n",
    "                          colsample_bytree=0.9)\n",
    "\n",
    "# perform cross validation\n",
    "cross_val(clf, full_train, y)\n",
    "\n",
    "# generate file for Kaggle\n",
    "# clf.fit(full_train, y)\n",
    "# pred = clf.predict(full_test)\n",
    "# test_set_df=pd.read_csv('../input/2b-training/test_without_labels.csv')\n",
    "# pred_df = pd.DataFrame(data={\"Predicted\": pred}, index=test_set_df['Id'])\n",
    "# pred_df.to_csv('testSet_categoriescsv')\n",
    "\n"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": "Attempting 5-fold cross validation...\nAccuracy: 0.7463216140158595 [0.74733662 0.74648858 0.74668292 0.74272539 0.74837456]\nPrecision: 0.7439042461095585 [0.74454819 0.7443002  0.7446263  0.74033704 0.74570949]\nRecall: 0.7610651825073024 [0.76172476 0.7615075  0.76186636 0.75724943 0.76297786]\nF-Measure: 0.7413735645553698 [0.74229339 0.74161431 0.7418519  0.73771761 0.74339061]\nFit-Time: 123.09309844970703 [124.4544189  125.14486599 124.84476137 117.46773767 123.55370831]\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}